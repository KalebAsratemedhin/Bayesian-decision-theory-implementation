{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://github.com/YBIFoundation/Dataset/raw/main/Cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianDecisionTheory:\n",
    "    def __init__(self, priors, likelihoods, loss_matrix=None):\n",
    "        \"\"\"\n",
    "        Initialize the Bayesian Decision Theory class.\n",
    "\n",
    "        :param priors: Array of prior probabilities P(Ci)\n",
    "        :param likelihoods: 2D array of likelihood probabilities P(X|Ci)\n",
    "                            Rows correspond to classes, columns to features.\n",
    "        :param loss_matrix: 2D array of loss values λik (optional).\n",
    "                            Defaults to 0/1 loss.\n",
    "        \"\"\"\n",
    "        self.priors = np.array(priors)\n",
    "        self.likelihoods = np.array(likelihoods)\n",
    "        self.num_classes = len(priors)\n",
    "        self.loss_matrix = loss_matrix if loss_matrix is not None else self._default_loss_matrix()\n",
    "\n",
    "    def _default_loss_matrix(self):\n",
    "        \"\"\"\n",
    "        Generate a default 0/1 loss matrix.\n",
    "        \"\"\"\n",
    "        loss = np.ones((self.num_classes, self.num_classes))\n",
    "        np.fill_diagonal(loss, 0)\n",
    "        return loss\n",
    "\n",
    "    def posterior_probabilities(self, feature_vector):\n",
    "        \"\"\"\n",
    "        Calculate posterior probabilities for a given feature vector.\n",
    "\n",
    "        :param feature_vector: Array of observed features X.\n",
    "        :return: Array of posterior probabilities P(Ci|X).\n",
    "        \"\"\"\n",
    "        evidence = sum(\n",
    "            self.priors[i] * np.prod(self.likelihoods[i] ** feature_vector)\n",
    "            for i in range(self.num_classes)\n",
    "        )\n",
    "        posteriors = [\n",
    "            (self.priors[i] * np.prod(self.likelihoods[i] ** feature_vector)) / evidence\n",
    "            for i in range(self.num_classes)\n",
    "        ]\n",
    "        return np.array(posteriors)\n",
    "\n",
    "    def classify(self, feature_vector):\n",
    "        \"\"\"\n",
    "        Classify a sample based on the posterior probabilities.\n",
    "\n",
    "        :param feature_vector: Array of observed features X.\n",
    "        :return: Predicted class index.\n",
    "        \"\"\"\n",
    "        posteriors = self.posterior_probabilities(feature_vector)\n",
    "        return np.argmax(posteriors)\n",
    "\n",
    "    def calculate_risk(self, feature_vector):\n",
    "        \"\"\"\n",
    "        Calculate the risk for each class.\n",
    "\n",
    "        :param feature_vector: Array of observed features X.\n",
    "        :return: Array of risks for each class.\n",
    "        \"\"\"\n",
    "        posteriors = self.posterior_probabilities(feature_vector)\n",
    "        risks = [np.dot(self.loss_matrix[i], posteriors) for i in range(self.num_classes)]\n",
    "        return np.array(risks)\n",
    "\n",
    "    def classify_with_risk(self, feature_vector):\n",
    "        \"\"\"\n",
    "        Classify a sample based on the risk minimization principle.\n",
    "\n",
    "        :param feature_vector: Array of observed features X.\n",
    "        :return: Predicted class index based on minimum risk.\n",
    "        \"\"\"\n",
    "        risks = self.calculate_risk(feature_vector)\n",
    "        return np.argmin(risks)\n",
    "\n",
    "    def classify_with_reject(self, feature_vector, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Classify a sample with a reject option based on a posterior threshold.\n",
    "\n",
    "        :param feature_vector: Array of observed features X.\n",
    "        :param threshold: Posterior probability threshold for rejection.\n",
    "        :return: Predicted class index or -1 for rejection.\n",
    "        \"\"\"\n",
    "        posteriors = self.posterior_probabilities(feature_vector)\n",
    "        max_posterior = np.max(posteriors)\n",
    "        if max_posterior < threshold:\n",
    "            return -1  # Reject class\n",
    "        return np.argmax(posteriors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior Probabilities: [0.18181818 0.81818182]\n",
      "Classified as: 1\n",
      "Risk for each class: [1.63636364 0.18181818]\n",
      "Classified based on risk: 1\n",
      "Classified with rejection (threshold 0.5): 1\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "\n",
    "# Define priors, likelihoods, and a custom loss matrix\n",
    "priors = [0.4, 0.6]  # Prior probabilities for two classes\n",
    "likelihoods = [\n",
    "    [0.2, 0.8],  # Likelihoods for class C1\n",
    "    [0.6, 0.4]   # Likelihoods for class C2\n",
    "]\n",
    "loss_matrix = [\n",
    "    [0, 2],  # Loss for predicting C1 when true class is C1 or C2\n",
    "    [1, 0]   # Loss for predicting C2 when true class is C1 or C2\n",
    "]\n",
    "feature_vector = [1, 0]  # Observed feature vector\n",
    "\n",
    "# Create the Bayesian Decision Theory model\n",
    "model = BayesianDecisionTheory(priors, likelihoods, loss_matrix)\n",
    "\n",
    "# Perform classifications\n",
    "print(\"Posterior Probabilities:\", model.posterior_probabilities(feature_vector))\n",
    "print(\"Classified as:\", model.classify(feature_vector))\n",
    "print(\"Risk for each class:\", model.calculate_risk(feature_vector))\n",
    "print(\"Classified based on risk:\", model.classify_with_risk(feature_vector))\n",
    "print(\"Classified with rejection (threshold 0.5):\", model.classify_with_reject(feature_vector, threshold=0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/YBIFoundation/Dataset/raw/main/Cancer.csv\"\n",
    "try:\n",
    "    dataset = pd.read_csv(url)\n",
    "    print(\"Dataset downloaded successfully!\")\n",
    "    print(dataset.head())  # Display the first 5 rows\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 33)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaleb/projects/ML/Bayesian-decision-theory-implementation/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/kaleb/projects/ML/Bayesian-decision-theory-implementation/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/kaleb/projects/ML/Bayesian-decision-theory-implementation/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[71  0]\n",
      " [43  0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77        71\n",
      "           1       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.62       114\n",
      "   macro avg       0.31      0.50      0.38       114\n",
      "weighted avg       0.39      0.62      0.48       114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaleb/projects/ML/Bayesian-decision-theory-implementation/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kaleb/projects/ML/Bayesian-decision-theory-implementation/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kaleb/projects/ML/Bayesian-decision-theory-implementation/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n",
    "X = data.iloc[:, 2:].values  \n",
    "y = data['diagnosis'].values\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Estimate priors and likelihoods\n",
    "priors = [np.mean(y_train == 0), np.mean(y_train == 1)]\n",
    "likelihoods = []\n",
    "\n",
    "for class_idx in [0, 1]:\n",
    "    class_features = X_train[y_train == class_idx]\n",
    "    feature_means = np.mean(class_features, axis=0)\n",
    "    feature_variances = np.var(class_features, axis=0)\n",
    "    likelihoods.append([1 / np.sqrt(2 * np.pi * var) for var in feature_variances])\n",
    "\n",
    "likelihoods = np.array(likelihoods)\n",
    "\n",
    "# Define a custom loss matrix\n",
    "loss_matrix = [\n",
    "    [0, 2],  # Loss for predicting benign when true class is malignant\n",
    "    [1, 0]   # Loss for predicting malignant when true class is benign\n",
    "]\n",
    "\n",
    "# Create the Bayesian Decision Theory model\n",
    "model = BayesianDecisionTheory(priors, likelihoods, loss_matrix)\n",
    "\n",
    "# Perform predictions and evaluate\n",
    "predictions = [model.classify_with_risk(x) for x in X_test]\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
